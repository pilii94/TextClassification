{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect a candidate to develop a solution that is capable to classify provided texts in one of **four** classes.\n",
    " \n",
    "You may find the dataset in the **data** folder:\n",
    "- train.csv contains training dataset. There are four columns in this file:\n",
    "    - id - column with unique identifier of each data sample\n",
    "    - category - target variable\n",
    "    - title - document title\n",
    "    - description - document text\n",
    "- test.csv contains test dataset and all the columns are the same except category as it is unknown and should be predicted.\n",
    "- sample_submission.csv - an example of how resulting submission shoul look like.\n",
    "\n",
    "Your model should give as an output a probability of each sample belonging to each class.\n",
    "\n",
    "To submit your solution put this **solution.ipynb** file and generated **submission.csv** in a **zip** file.\n",
    "\n",
    "We are interested to see how candidate implements his/her typical pipeline to solve machine learning problems starting with a dataset containing both data and target variable.\n",
    "\n",
    "We **do not** expect a state-of-the-art solution here, rather a code that demonstrates candidate's understanding of crucial parts in ML models development. However, it would be a plus to see a brief description on how to get to the near-state-of-the-art solution in conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# add needed libraries here\n",
    "from utils import ReplaceDiatrics,PunctRemove,Tfidf_fit,Tfidf_transform,PreprocessText\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code in this and the following blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    30000\n",
       "2    30000\n",
       "1    30000\n",
       "0    30000\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "#check dataset balance\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Text Preprocessing Started-----\n",
      " ----Removing Stopwords---- \n",
      " ----Removing Diatrics---- \n",
      " ----Removing Punctuation---- \n",
      "-----Text Preprocessing Finished-----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#we will work with both texts together\n",
    "df[\"text_0\"]=df[\"title\"]+df[\"description\"]\n",
    "\n",
    "\n",
    "\n",
    "processed_df=PreprocessText(df)\n",
    "processed_df.head()\n",
    "\n",
    "X,y=processed_df.text_0,processed_df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Tfidf fitting-----\n",
      "-----Tfidf transforming-----\n"
     ]
    }
   ],
   "source": [
    "#train vectorizer and transform text\n",
    "Tfidf_fit(X)\n",
    "X=Tfidf_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score ->  0.9164324581721721\n"
     ]
    }
   ],
   "source": [
    "#select best hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "SVM = Pipeline([('clf', SVC(random_state=1,C=10.0,probability=True))])\n",
    "'''\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range,\n",
    "               'clf__kernel': ['linear']},\n",
    "              {'clf__C': param_range,\n",
    "               'clf__gamma': param_range,\n",
    "               'clf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=SVM,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='f1_macro',\n",
    "                  cv=10,\n",
    "                  n_jobs=1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print('--> Best score: ',gs.best_score_)\n",
    "print('--> Best parameters: \\n',gs.best_params_)\n",
    "\n",
    "\n",
    "#Select best parameters\n",
    "\n",
    "SVM = gs.best_estimator_\n",
    "'''\n",
    "#final values\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict labels on validation set\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "# Use f1 score function \n",
    "print(\"F1 Score -> \",f1_score(y_test, predictions_SVM, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##store model\n",
    "pickle.dump(SVM, open('svm.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Text Preprocessing Started-----\n",
      " ----Removing Stopwords---- \n",
      " ----Removing Diatrics---- \n",
      " ----Removing Punctuation---- \n",
      "-----Text Preprocessing Finished-----\n",
      "-----Tfidf transforming-----\n",
      "F1 Score ->  0.9085468938415864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1725,   48,   69,   58],\n",
       "       [  19, 1849,   17,   15],\n",
       "       [  68,   14, 1652,  166],\n",
       "       [  70,   19,  131, 1680]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read test data\n",
    "test_df=pd.read_csv(\"data/test.csv\")\n",
    "test_answers_df=pd.read_csv(\"data/test_answers.csv\")\n",
    "\n",
    "test_df=pd.merge(test_df, test_answers_df, on=\"id\") \n",
    "\n",
    "test_df[\"text_0\"]=test_df[\"title\"]+test_df[\"description\"]\n",
    "\n",
    "\n",
    "\n",
    "processed_test_df=PreprocessText(test_df)\n",
    "X_t=processed_test_df.text_0\n",
    "X_t=Tfidf_transform(X_t)\n",
    "\n",
    "\n",
    "svm_model=pickle.load(open('svm.sav', 'rb'))\n",
    "\n",
    "\n",
    "predicted_cat=svm_model.predict(X_t)\n",
    "prob_classes=svm_model.predict_proba(X_t)\n",
    "test_df[\"pred_category\"]=predicted_cat\n",
    "\n",
    "\n",
    "print(\"F1 Score -> \",f1_score(test_df[\"category\"], test_df[\"pred_category\"], average='macro'))\n",
    "confusion_matrix(test_df[\"category\"],test_df[\"pred_category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=prob_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the following code to generate a submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_df['id']\n",
    "submission['category_0'] = predictions[:, 0]\n",
    "submission['category_1'] = predictions[:, 1]\n",
    "submission['category_2'] = predictions[:, 2]\n",
    "submission['category_3'] = predictions[:, 3]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colnclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a few words about your solution here. \n",
    "\n",
    "I developed a text classification pipeline that includes training a TFIDF model to vectorize text prior to training the linear SVM model. Text processing is crucial to get good results. I did not apply stemming or lemmatization as text quality is good as is and sometimes it can be counterproductive.\n",
    "\n",
    "- What could be improved? \n",
    "\n",
    "Hyperparameter tunning could be done with a wider range of values and the whole dataset. Instead of Grid search, Bayesian Optimization could be used.\n",
    "\n",
    "- What approaches may work as well for this problem? \n",
    "\n",
    "Convolutional Neural Networks, Random Forest, Naive Bayes, vectorizers: Bag of Words, Word embeddings\n",
    "\n",
    "- What would you implement if you have had more time for this task?\n",
    "\n",
    "A CNN\n",
    "\n",
    "- Feel free to write anything you think is relevant to this task :)\n",
    "\n",
    " I applied Grid Search for parameter tunning with a subset of data (for time and memory matters) to select parameter 'C'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
